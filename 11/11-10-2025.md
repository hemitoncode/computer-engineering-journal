## Date:
Monday, November 10th

## Vector embeddings!!

### Introduction:
Today, we did more practice on circuit analysis. I was pretty confident in my abilities to do it, so I decided to write on an interesting article that I read.

### Learning/Reflections:
I am building an AI app (www.nextvoters.com/team) which requires an understanding of vector embeddings. A vector embedding is a way to represent words with numbers. Just like any other vector... it has a **direction** and **size**.

AI systems are machines, which means they thrive on structure and patterns. However, raw text does not have any structure because it is a human creation. It can have deep underlying emotions which cannot be grasped by a mathemtical model. This is why we have to take words and *vectorize* them, so the AI model can understand them properly. 

Vector embeddings are not exclusive to words. It is applicable to all "unstructured" data which cannot easily be understood through patterns. Examples of other things that can be vectorized are images, videos, and audios. 

https://www.datacamp.com/blog/vector-embedding

<img width="507" height="554" alt="image" src="https://github.com/user-attachments/assets/8311e189-ac84-4a30-a536-a597988b315a" />

### Conclusion:
In conclusion, today I understood the importance of vector embeddings in an AI system, making me more apperciative of why I must use a embedding model to convert my words into numerical representations. 
